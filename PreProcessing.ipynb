{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67bcca90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Input, Model\n",
    "from tensorflow.keras.layers import (\n",
    "    Conv1D, BatchNormalization, MaxPooling1D,\n",
    "    Bidirectional, LSTM, Dropout, Dense, Lambda, Layer, Masking\n",
    ")\n",
    "from tensorflow.keras.regularizers import l2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from hmmlearn import hmm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report\n",
    "import random\n",
    "import warnings\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a7ff223",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Estrazione e Salvataggio:\n",
    " 1) Feature globali (966) per Utterance -> emovo_features.xlsx\n",
    " 2) Feature locali (23 LLD + 23 Δ) per Frame -> emovo_frame_features.xlsx\n",
    "\"\"\"\n",
    "\n",
    "if not hasattr(np, 'complex'): np.complex = complex\n",
    "if not hasattr(np, 'float'):   np.float   = float\n",
    "\n",
    "# Configurazione\n",
    "AUDIO_DIR = #...\n",
    "SAVE_DIR  = #...\n",
    "OUT_GLOBAL  = \"emovo_global_features.xlsx\"\n",
    "OUT_LOCAL  = \"emovo_local_features.xlsx\"\n",
    "# 32 ms @16 kHz -> 512 campioni; hop 8 ms -> 128 campioni\n",
    "WIN_LENGTH = 512\n",
    "HOP_LENGTH = 128\n",
    "\n",
    "emo_map = {\n",
    "    \"dis\": \"Disgust\",\n",
    "    \"gio\": \"Happiness\",\n",
    "    \"pau\": \"Fear\",\n",
    "    \"rab\": \"Anger\",\n",
    "    \"sor\": \"Surprise\",\n",
    "    \"tri\": \"Sadness\",\n",
    "    \"neu\": \"Neutral\"\n",
    "}\n",
    "\n",
    "def compute_stats(vec):\n",
    "    #Calcolo delle 21 statistiche su un vettore 1-D.\n",
    "    n = len(vec)\n",
    "    t = np.arange(n)\n",
    "    a, b = np.polyfit(t, vec, 1)\n",
    "    pred = a*t + b\n",
    "    err = vec - pred\n",
    "    q25, q50, q75 = np.percentile(vec, [25,50,75])\n",
    "    vmin,vmax = vec.min(), vec.max()\n",
    "    thr75 = vmin + 0.75*(vmax-vmin)\n",
    "    thr90 = vmin + 0.90*(vmax-vmin)\n",
    "    return {\n",
    "        \"maxPos\": np.argmax(vec)/n,\n",
    "        \"minPos\": np.argmin(vec)/n,\n",
    "        \"amean\":  vec.mean(),\n",
    "        \"stddev\": vec.std(),\n",
    "        \"linregc1\": a,\n",
    "        \"linregc2\": b,\n",
    "        \"linregerrA\": np.mean(np.abs(err)),\n",
    "        \"linregerrQ\": np.mean(err**2),\n",
    "        \"quartile1\": q25,\n",
    "        \"quartile2\": q50,\n",
    "        \"quartile3\": q75,\n",
    "        \"kurtosis\": stats.kurtosis(vec,fisher=True,bias=False),\n",
    "        \"skewness\": stats.skew(vec,bias=False),\n",
    "        \"iqr1_2\": q50-q25,\n",
    "        \"iqr2_3\": q75-q50,\n",
    "        \"iqr1_3\": q75-q25,\n",
    "        \"percentile1\":  np.percentile(vec,1),\n",
    "        \"percentile99\": np.percentile(vec,99),\n",
    "        \"pctlrange0_1\": np.percentile(vec,1)-vmin,\n",
    "        \"upleveltime75\": np.mean(vec>thr75),\n",
    "        \"upleveltime90\": np.mean(vec>thr90),\n",
    "    }\n",
    "\n",
    "def extract_framewise(y, sr):\n",
    "    \"\"\"\n",
    "    Restituisce:\n",
    "      - frame_feats: array (T,46) di [MFCC0-14, LogMel0-7, ΔMFCC, ΔLogMel]\n",
    "      - hdr       : lista di 46 nomi colonna\n",
    "    \"\"\"\n",
    "    # MFCC e LogMel con overlap\n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=15,\n",
    "                                n_fft=WIN_LENGTH,\n",
    "                                hop_length=HOP_LENGTH,\n",
    "                                win_length=WIN_LENGTH)\n",
    "    mel = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=8,\n",
    "                                         n_fft=WIN_LENGTH,\n",
    "                                         hop_length=HOP_LENGTH,\n",
    "                                         win_length=WIN_LENGTH,\n",
    "                                         fmax=8000)\n",
    "    logmel = librosa.power_to_db(mel)\n",
    "    lld = np.vstack([mfcc, logmel])                # (23, T)\n",
    "    delta = librosa.feature.delta(lld, order=1)     # (23, T)\n",
    "\n",
    "    hdr = [f\"mfcc{i}\" for i in range(15)] + \\\n",
    "          [f\"logmel{i}\" for i in range(8)] + \\\n",
    "          [f\"dmfcc{i}\" for i in range(15)] + \\\n",
    "          [f\"dlogmel{i}\" for i in range(8)]\n",
    "    # Costruzione matrice Tx46\n",
    "    feat = np.hstack([lld.T, delta.T])\n",
    "    return feat, hdr\n",
    "\n",
    "def extract_global_stats(frame_feats, hdr):\n",
    "    \"\"\"\n",
    "    Calcolo delle statistiche globali su ciascuna colonna di frame_feats\n",
    "    Restituisce dict {<hdr>_<stat>:val, ...}\n",
    "    \"\"\"\n",
    "    stats_dict = {}\n",
    "    for col, name in enumerate(hdr):\n",
    "        colvec = frame_feats[:,col]\n",
    "        s = compute_stats(colvec)\n",
    "        for k,v in s.items():\n",
    "            stats_dict[f\"{name}_{k}\"] = v\n",
    "    return stats_dict\n",
    "\n",
    "def main():\n",
    "    rows_global = []\n",
    "    rows_frames = []\n",
    "    for root,_,files in os.walk(AUDIO_DIR):\n",
    "        for fn in files:\n",
    "            if not fn.lower().endswith(('.wav','.flac','.ogg','.mp3')):\n",
    "                continue\n",
    "            base,_ = os.path.splitext(fn)\n",
    "            parts = base.split('-')\n",
    "            if len(parts)<3:\n",
    "                print(f\"[SKIP] {fn}\")\n",
    "                continue\n",
    "            emo_code = parts[0]\n",
    "            emo = emo_map.get(emo_code, emo_code)\n",
    "            speaker,utt = parts[1],parts[2]\n",
    "            path = os.path.join(root,fn)\n",
    "\n",
    "            # Caricamento audio Stereo/Mono\n",
    "            y,sr = librosa.load(path, sr=16000, mono=False)\n",
    "            if y.ndim>1: y = y.mean(axis=0)\n",
    "\n",
    "            # Estrazione feature frame-wise\n",
    "            feat_mat, hdr = extract_framewise(y,sr)\n",
    "            T,_ = feat_mat.shape\n",
    "\n",
    "            # frame-wise -> rows_frames\n",
    "            for t in range(T):\n",
    "                rowf = {\n",
    "                    \"file\":fn,\"emotion\":emo,\"speaker\":speaker,\"utt_id\":utt,\"frame\":t\n",
    "                }\n",
    "                for i,name in enumerate(hdr):\n",
    "                    rowf[name] = float(feat_mat[t,i])\n",
    "                rows_frames.append(rowf)\n",
    "\n",
    "            # global stats -> rows_global\n",
    "            gs = extract_global_stats(feat_mat, hdr)\n",
    "            rowg = {\"file\":fn,\"emotion\":emo,\"speaker\":speaker,\"utt_id\":utt}\n",
    "            rowg.update(gs)\n",
    "            rows_global.append(rowg)\n",
    "            print(f\"{fn}: {T} frame estratti\")\n",
    "\n",
    "    # Salvataggio DataFrame globali\n",
    "    dfg = pd.DataFrame(rows_global)\n",
    "    dff = pd.DataFrame(rows_frames)\n",
    "\n",
    "    # Ordinamento\n",
    "    dfg.sort_values([\"speaker\",\"emotion\",\"utt_id\"], inplace=True)\n",
    "    dff.sort_values([\"speaker\",\"emotion\",\"utt_id\",\"frame\"], inplace=True)\n",
    "\n",
    "    # Creazione della cartella di salvataggio\n",
    "    os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "    # Salvataggio\n",
    "    out_g = os.path.join(SAVE_DIR, OUT_GLOBAL)\n",
    "    out_f = os.path.join(SAVE_DIR, OUT_LOCAL)\n",
    "    dfg.to_excel(out_g, index=False)\n",
    "    dff.to_excel(out_f, index=False)\n",
    "    print(f\"\\nGlobal features -> {out_g}\")\n",
    "    print(f\"Frame features  -> {out_f}\")\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
